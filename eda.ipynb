{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65499, 3)\n",
      "(64458, 3)\n",
      "(64434, 3)\n",
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "verbose = False\n",
    "np.random.seed(14)\n",
    "input_csv = \"data/snippets.csv\"\n",
    "full = pd.read_csv(input_csv) # , header=None)\n",
    "print full.shape\n",
    "\n",
    "full = full.dropna(axis=0)\n",
    "print full.shape\n",
    "\n",
    "full = full[full['Content'].str.len() < 600]\n",
    "print full.shape\n",
    "\n",
    "full = full[0:10000]\n",
    "print full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preX = full['Content']\n",
    "preX = preX.apply(lambda row: row.strip())\n",
    "preX = preX.apply(lambda row: row.replace('-', ' '))\n",
    "parsed = preX.apply(lambda row: nlp(unicode(row, 'utf-8', 'ignore')) )\n",
    "reindexed = parsed.reset_index(drop=True)\n",
    "# X = reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2500\n",
      "5000\n",
      "7500\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "postX = []\n",
    "for idx, sentence in enumerate(preX):\n",
    "    found_entities = []\n",
    "    for ent in reindexed[idx].ents:\n",
    "        if ent.label_ == 'ORG':\n",
    "            found_entities.append( (ent.text.encode('utf-8'), 'ORG') )\n",
    "        if ent.label_ == 'PERSON':\n",
    "            found_entities.append( (ent.text.encode('utf-8'), 'PERSON') )\n",
    "#         if ent.label_ == 'MONEY':\n",
    "#             found_entities.append( (ent.text.encode('utf-8'), 'MONEY') )\n",
    "    for word in found_entities:\n",
    "        sentence = sentence.replace(word[0], word[1])\n",
    "    postX.append(sentence)\n",
    "    if (idx%2500 == 0):\n",
    "        print idx\n",
    "\n",
    "postX = pd.Series(postX)\n",
    "parsed = postX.map(lambda row: nlp(unicode(row, 'utf-8', 'ignore')) )\n",
    "tokenized = parsed.map(lambda row: [token.orth_ for token in row])\n",
    "X = tokenized\n",
    "\n",
    "print len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = full['Tags']\n",
    "\n",
    "y = y.str.split(';').str[0]\n",
    "# print y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "funding        1511\n",
      "strategy       1502\n",
      "hire            825\n",
      "partnership     818\n",
      "product         721\n",
      "acquisition     668\n",
      "revenue         662\n",
      "OTHER           468\n",
      "overview        447\n",
      "users           425\n",
      "headcount       375\n",
      "award           368\n",
      "valuation       198\n",
      "turmoil         170\n",
      "founding        167\n",
      "customers       156\n",
      "market          154\n",
      "departure       131\n",
      "sector          101\n",
      "ipo              76\n",
      "competitors      57\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = y.str.replace('total-', '')\n",
    "y = y.str.replace('filing-', '')\n",
    "y = y.str.replace('key_person_', '')\n",
    "\n",
    "y = y.str.replace('lawsuit', 'OTHER')\n",
    "y = y.str.replace('office_move', 'OTHER')\n",
    "y = y.str.replace('geo', 'OTHER')\n",
    "y = y.str.replace('reorg', 'OTHER')\n",
    "y = y.str.replace('patent', 'OTHER')\n",
    "y = y.str.replace('conference-sponsorship', 'OTHER')\n",
    "y = y.str.replace('executive-promotion', 'OTHER')\n",
    "y = y.str.replace('bankruptcy', 'OTHER')\n",
    "y = y.str.replace('event-participant', 'OTHER')\n",
    "y = y.str.replace('scale', 'OTHER')\n",
    "y = y.str.replace('team-grew', 'OTHER')\n",
    "y = y.str.replace('executive-publication', 'OTHER')\n",
    "y = y.str.replace('job-posting', 'OTHER')\n",
    "y = y.str.replace('leadership-change', 'OTHER')\n",
    "\n",
    "y = y.fillna('OTHER')\n",
    "jake = y.value_counts()\n",
    "print len(jake)\n",
    "print jake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = y.reset_index(drop=True)\n",
    "y = y[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for exp in X:\n",
    "    if (len(exp) > max):\n",
    "        max = len(exp)\n",
    "print max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "print y.shape\n",
    "y.name=\"Tags\"\n",
    "print X.shape\n",
    "X.name=\"Content\"\n",
    "data = pd.concat([X, y], axis=1)\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content         Tags  Tokens\n",
      "0  [PERSON, ,, creators, of, the, first, guided, ...      funding      36\n",
      "1  [ORG, ,, the, new, venture, by, ORG, founders,...     overview      23\n",
      "2  [The, firm, will, launch, a, beta, program, in...      product      30\n",
      "3  [ORG, has, added, task, management, to, its, s...      product      22\n",
      "4  [But, with, this, latest, release, ,, the, goa...  competitors      32\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "data['Tokens'] = data.apply(lambda row: len(row[\"Content\"]), axis=1)\n",
    "print data.head()\n",
    "print len(data)\n",
    "# print type(buck10)\n",
    "# print len(buck10)\n",
    "# print buck10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buck1 = data[ data[\"Tokens\"]<=10 ]\n",
    "buck2 = data[ (data[\"Tokens\"]<=20) & (data[\"Tokens\"]>10) ]\n",
    "buck3 = data[ (data[\"Tokens\"]<=30) & (data[\"Tokens\"]>20) ]\n",
    "buck4 = data[ (data[\"Tokens\"]<=40) & (data[\"Tokens\"]>30) ]\n",
    "buck5 = data[ (data[\"Tokens\"]<=50) & (data[\"Tokens\"]>40) ]\n",
    "buck6 = data[ (data[\"Tokens\"]<=60) & (data[\"Tokens\"]>50) ]\n",
    "buck7 = data[ (data[\"Tokens\"]<=80) & (data[\"Tokens\"]>60) ]\n",
    "buck8 = data[ data[\"Tokens\"]>80 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "1774\n",
      "3335\n",
      "2708\n",
      "1370\n",
      "460\n",
      "197\n",
      "28\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "myBuks = [buck10, buck20, buck30, buck40, buck50, buck60, buck80, buckmax]\n",
    "totalRows = 0\n",
    "\n",
    "for bucket in myBuks:\n",
    "    sep = len(bucket)\n",
    "    print sep\n",
    "    totalRows += sep\n",
    "\n",
    "print totalRows\n",
    "print len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print data['Content'][8771]\n",
    "# print data['Content'][10731]\n",
    "# print data['Content'][3451]\n",
    "#  Tricky token parsing: [10731, 37877, 8771, 3451, 42795]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(buck50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buck10.to_pickle('data/buck1.p')\n",
    "buck20.to_pickle('data/buck2.p')\n",
    "buck30.to_pickle('data/buck3.p')\n",
    "buck40.to_pickle('data/buck4.p')\n",
    "buck50.to_pickle('data/buck5.p')\n",
    "buck60.to_pickle('data/buck6.p')\n",
    "buck80.to_pickle('data/buck7.p')\n",
    "buckmax.to_pickle('data/buck8.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
